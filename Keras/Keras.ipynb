{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b1cf6b4",
   "metadata": {},
   "source": [
    "## Generate Datasets\n",
    "\n",
    "### Dataset Distribution\n",
    "\n",
    "In order to look at the dataset distribution and evaluate its balance, I would create a dataframe with 2 columns:\n",
    "- 1st column: name of the image file\n",
    "- 2nd column: label for that image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e4f851a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-24 14:13:16.507166: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-06-24 14:13:16.522746: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1750767196.543165   39878 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1750767196.550049   39878 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1750767196.564893   39878 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1750767196.564916   39878 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1750767196.564918   39878 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1750767196.564920   39878 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-06-24 14:13:16.569718: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "509f8286",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GET THE DIRECTORY TO THE DATASETS\n",
    "path_data = '../chest_Xray/'\n",
    "path_train = os.path.join(path_data, 'train')\n",
    "path_val = os.path.join(path_data, 'val')\n",
    "path_test = os.path.join(path_data, 'test')\n",
    "\n",
    "# INITIATE EMPTY LIST OF TRAINING DATA\n",
    "# THAT WILL BE CONVERTED TO PANDAS DATAFRAME LATER\n",
    "data_train = []\n",
    "data_val = []\n",
    "data_test = []\n",
    "data = [data_train, data_val, data_test]\n",
    "\n",
    "# ITERATE THROUGH EACH PATH\n",
    "for i, d in enumerate([path_train, path_val, path_test]):\n",
    "    # GET THE PATH TO EACH FOLDER - NORMAL AND PNEUMONIA\n",
    "    normal = os.path.join(d, 'NORMAL')\n",
    "    pneumonia = os.path.join(d, 'PNEUMONIA')\n",
    "    \n",
    "    # FETCH ALL .jpeg FILES\n",
    "    normal_imgs = Path(normal).glob('*.jpeg')\n",
    "    pneumonia_imgs = Path(pneumonia).glob('*.jpeg')\n",
    "    \n",
    "    # APPEND THE NAME AND CORRESPONDING LABEL (BASED ON FOLDER NAME)\n",
    "    # TO data_train list AS TUPLES\n",
    "    for img in normal_imgs:\n",
    "        data[i].append((str(img), 0))\n",
    "    \n",
    "    for img in pneumonia_imgs:\n",
    "        data[i].append((str(img), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2757031",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONVERT data_train TO DATAFRAME FOR EASY MANIPULATION\n",
    "columns = ['image', 'label']\n",
    "train_df = pd.DataFrame(data_train, columns=columns)\n",
    "val_df = pd.DataFrame(data_val, columns=columns)\n",
    "test_df = pd.DataFrame(data_test, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1031f08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONCAT train_df and val_df\n",
    "master_df = pd.concat([train_df, val_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee8a47a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cat_pneumonia_type(x):\n",
    "    if 'bacteria' in x:\n",
    "        output = 'bacteria'\n",
    "    elif 'virus' in x:\n",
    "        output = 'virus'\n",
    "    else:\n",
    "        output = 'normal'\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df24cf21",
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df['type'] = master_df.image.apply(lambda x: cat_pneumonia_type(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "36f56a29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "type\n",
       "bacteria    2538\n",
       "normal      1349\n",
       "virus       1345\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_df.type.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "544f00a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, val_df = train_test_split(master_df, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ebeee6",
   "metadata": {},
   "source": [
    "### Data Generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a10a3711",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4185 validated image filenames.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1047 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "# CREATE GENERATOR FOR TRAINING DATA (FROM train_df DATAFRAME)\n",
    "train_generator = ImageDataGenerator(rescale=1.0/255).flow_from_dataframe(\n",
    "    dataframe=train_df, x_col='image', y_col='label',\n",
    "    color_mode='grayscale',\n",
    "    class_mode='raw',\n",
    "    target_size=(128,128), \n",
    "    batch_size=BATCH_SIZE,\n",
    "    seed=42,\n",
    "    shuffle=True   # shuffle so we're not missing out on any samples\n",
    ")\n",
    "\n",
    "# CREATE GENERATOR FOR VALIDATION DATA (FROM val_df DATAFRAME)\n",
    "val_generator = ImageDataGenerator(rescale=1.0/255).flow_from_dataframe(\n",
    "    dataframe=val_df, x_col='image', y_col='label',\n",
    "    color_mode='grayscale',\n",
    "    class_mode='raw',\n",
    "    target_size=(128,128), \n",
    "    batch_size=BATCH_SIZE,\n",
    "    seed=42,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c2fbb9e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: (32, 128, 128, 1) | (32,)\n"
     ]
    }
   ],
   "source": [
    "# CHECKING THE SHAPE OF 1 BATCH OF THE train_generator\n",
    "images_train, labels_train = next(train_generator)\n",
    "print(f'Training set: {images_train.shape} | {labels_train.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae1b6ab",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "89f6a131",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Conv2D, Flatten, MaxPooling2D, Dropout\n",
    "from keras.metrics import Recall, Precision\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.optimizers.schedules import ExponentialDecay\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4221d936",
   "metadata": {},
   "source": [
    "### Baseline Model\n",
    "\n",
    "Baseline Convolution Neural Networks (CNN) model with:\n",
    "\n",
    "- One 2D Convolution layer with padding (same) and ReLU activation\n",
    "- One 2D MaxPooling layer\n",
    "- A Flatten layer to convert the 2D feature maps into a 1D vector\n",
    "- One hidden Dense (fully connected) layer with ReLU activation\n",
    "- One output Dense layer with a sigmoid activation for binary classification\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b8042875",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/corentin/.pyenv/versions/3.10.12/envs/test/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "I0000 00:00:1750767200.267214   39878 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4124 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "baseline = Sequential()\n",
    "baseline.add(Conv2D(32, (3,3), activation='relu', padding='same', input_shape=[128,128,1]))\n",
    "baseline.add(MaxPooling2D(pool_size=(2,2)))\n",
    "baseline.add(Flatten())\n",
    "baseline.add(Dense(32, activation='relu'))\n",
    "baseline.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2b8486dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "recall = Recall()\n",
    "precision = Precision()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "778efa95",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline.compile(loss='binary_crossentropy',\n",
    "                 optimizer='adam',\n",
    "                 metrics=['accuracy', recall, precision])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d5b6ba52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">131072</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │     <span style=\"color: #00af00; text-decoration-color: #00af00\">4,194,336</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m320\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m131072\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │     \u001b[38;5;34m4,194,336\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m33\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,194,689</span> (16.00 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,194,689\u001b[0m (16.00 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,194,689</span> (16.00 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m4,194,689\u001b[0m (16.00 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "baseline.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2881e51d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/corentin/.pyenv/versions/3.10.12/envs/test/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1750767202.818312   39964 service.cc:152] XLA service 0x7f20540043c0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1750767202.818335   39964 service.cc:160]   StreamExecutor device (0): NVIDIA GeForce RTX 3060 Laptop GPU, Compute Capability 8.6\n",
      "2025-06-24 14:13:22.870771: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1750767203.078434   39964 cuda_dnn.cc:529] Loaded cuDNN version 91002\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m  1/130\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7:41\u001b[0m 4s/step - accuracy: 0.8438 - loss: 0.6567 - precision: 0.8438 - recall: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1750767205.113813   39964 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 170ms/step - accuracy: 0.8575 - loss: 0.5795 - precision: 0.8827 - recall: 0.9402"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 220ms/step - accuracy: 0.8579 - loss: 0.5772 - precision: 0.8831 - recall: 0.9403 - val_accuracy: 0.9590 - val_loss: 0.1082 - val_precision: 0.9580 - val_recall: 0.9865\n",
      "Epoch 2/30\n",
      "\u001b[1m  1/130\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 46ms/step - accuracy: 1.0000 - loss: 0.0425 - precision: 1.0000 - recall: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/corentin/.pyenv/versions/3.10.12/envs/test/lib/python3.10/site-packages/keras/src/trainers/epoch_iterator.py:116: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self._interrupted_warning()\n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0425 - precision: 1.0000 - recall: 1.0000 - val_accuracy: 0.9648 - val_loss: 0.0987 - val_precision: 0.9706 - val_recall: 0.9811\n",
      "Epoch 3/30\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step - accuracy: 0.9663 - loss: 0.0938 - precision: 0.9745 - recall: 0.9807"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 202ms/step - accuracy: 0.9663 - loss: 0.0938 - precision: 0.9745 - recall: 0.9807 - val_accuracy: 0.9648 - val_loss: 0.0900 - val_precision: 0.9668 - val_recall: 0.9851\n",
      "Epoch 4/30\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0330 - precision: 1.0000 - recall: 1.0000 - val_accuracy: 0.9629 - val_loss: 0.0922 - val_precision: 0.9617 - val_recall: 0.9878\n",
      "Epoch 5/30\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 159ms/step - accuracy: 0.9723 - loss: 0.0702 - precision: 0.9797 - recall: 0.9830"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 202ms/step - accuracy: 0.9723 - loss: 0.0702 - precision: 0.9798 - recall: 0.9830 - val_accuracy: 0.9697 - val_loss: 0.0750 - val_precision: 0.9758 - val_recall: 0.9824\n",
      "Epoch 6/30\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 43ms/step - accuracy: 0.9375 - loss: 0.0938 - precision: 0.9545 - recall: 0.9545 - val_accuracy: 0.9658 - val_loss: 0.0807 - val_precision: 0.9876 - val_recall: 0.9649\n",
      "Epoch 7/30\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 202ms/step - accuracy: 0.9869 - loss: 0.0373 - precision: 0.9922 - recall: 0.9903 - val_accuracy: 0.9639 - val_loss: 0.0873 - val_precision: 0.9916 - val_recall: 0.9583\n",
      "Epoch 8/30\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 0.0188 - precision: 1.0000 - recall: 1.0000 - val_accuracy: 0.9609 - val_loss: 0.1010 - val_precision: 0.9916 - val_recall: 0.9540\n",
      "Epoch 9/30\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 156ms/step - accuracy: 0.9899 - loss: 0.0295 - precision: 0.9939 - recall: 0.9926"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 200ms/step - accuracy: 0.9899 - loss: 0.0295 - precision: 0.9939 - recall: 0.9926 - val_accuracy: 0.9678 - val_loss: 0.0744 - val_precision: 0.9706 - val_recall: 0.9851\n",
      "Epoch 10/30\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 0.0048 - precision: 1.0000 - recall: 1.0000 - val_accuracy: 0.9707 - val_loss: 0.0814 - val_precision: 0.9670 - val_recall: 0.9932\n",
      "Epoch 11/30\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step - accuracy: 0.9943 - loss: 0.0222 - precision: 0.9966 - recall: 0.9957"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 204ms/step - accuracy: 0.9943 - loss: 0.0222 - precision: 0.9966 - recall: 0.9957 - val_accuracy: 0.9717 - val_loss: 0.0656 - val_precision: 0.9851 - val_recall: 0.9758\n",
      "Epoch 12/30\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0232 - precision: 1.0000 - recall: 1.0000 - val_accuracy: 0.9697 - val_loss: 0.0722 - val_precision: 0.9848 - val_recall: 0.9728\n",
      "Epoch 13/30\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 197ms/step - accuracy: 0.9991 - loss: 0.0126 - precision: 0.9998 - recall: 0.9991 - val_accuracy: 0.9688 - val_loss: 0.0743 - val_precision: 0.9758 - val_recall: 0.9811\n",
      "Epoch 14/30\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 0.0223 - precision: 1.0000 - recall: 1.0000 - val_accuracy: 0.9697 - val_loss: 0.0747 - val_precision: 0.9758 - val_recall: 0.9824\n",
      "Epoch 15/30\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 199ms/step - accuracy: 0.9993 - loss: 0.0077 - precision: 0.9995 - recall: 0.9996 - val_accuracy: 0.9697 - val_loss: 0.0739 - val_precision: 0.9811 - val_recall: 0.9772\n",
      "Epoch 16/30\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 0.0054 - precision: 1.0000 - recall: 1.0000 - val_accuracy: 0.9697 - val_loss: 0.0770 - val_precision: 0.9797 - val_recall: 0.9784\n",
      "Epoch 17/30\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 199ms/step - accuracy: 0.9998 - loss: 0.0043 - precision: 1.0000 - recall: 0.9997 - val_accuracy: 0.9658 - val_loss: 0.0857 - val_precision: 0.9890 - val_recall: 0.9637\n",
      "Epoch 18/30\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 44ms/step - accuracy: 1.0000 - loss: 0.0218 - precision: 1.0000 - recall: 1.0000 - val_accuracy: 0.9648 - val_loss: 0.0971 - val_precision: 0.9903 - val_recall: 0.9609\n",
      "Epoch 19/30\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 199ms/step - accuracy: 1.0000 - loss: 0.0042 - precision: 1.0000 - recall: 1.0000 - val_accuracy: 0.9717 - val_loss: 0.0774 - val_precision: 0.9811 - val_recall: 0.9797\n",
      "Epoch 20/30\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 0.0026 - precision: 1.0000 - recall: 1.0000 - val_accuracy: 0.9707 - val_loss: 0.0769 - val_precision: 0.9811 - val_recall: 0.9784\n",
      "Epoch 21/30\n",
      "\u001b[1m130/130\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 203ms/step - accuracy: 1.0000 - loss: 0.0020 - precision: 1.0000 - recall: 1.0000 - val_accuracy: 0.9717 - val_loss: 0.0807 - val_precision: 0.9784 - val_recall: 0.9824\n"
     ]
    }
   ],
   "source": [
    "checkpoint_cb = ModelCheckpoint('baseline.h5',\n",
    "                                save_best_only=True)\n",
    "early_stopping_cb = EarlyStopping(patience=10, restore_best_weights=True)\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 30\n",
    "\n",
    "results_1 = baseline.fit(train_generator, \n",
    "                         validation_data=val_generator,\n",
    "                         epochs=EPOCHS,\n",
    "                         steps_per_epoch=(train_generator.n//BATCH_SIZE),\n",
    "                         validation_steps=(val_generator.n//BATCH_SIZE),\n",
    "                         callbacks=[checkpoint_cb, early_stopping_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ecca77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_training_results(results):\n",
    "    history = results.history\n",
    "    \n",
    "    for m in ['loss', 'accuracy', 'precision', 'recall']:\n",
    "        plt.figure(figsize=(15,5))\n",
    "        plt.plot(history[m], label='Training', marker='o', color='blue')\n",
    "        plt.plot(history[f'val_{m}'], label='Validation', marker='o', color='red')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.legend()\n",
    "        plt.title(m.title())\n",
    "    \n",
    "    plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b5746506",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_training_results(results_1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
